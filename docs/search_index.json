[
["index.html", "Opioid Environment Toolkit Preface", " Opioid Environment Toolkit Created by : Center for Spatial Data Science `Last Updated : 2020-10-04 Preface This bookdown project provides an overview of the basic spatial analytics for the JCOIN network developed by the team at the Center for Spatial Data Science at the University of Chicago. Our team is a part of the Policy and Practice Observational and Survey Research Core of the JCOIN network, within the Methodology and Advanced Analytic Resource Center (MAARC). Our goal is to develop a comprehensive toolkit that will allow practitioners to support their communities with better data analytics and visualization services. We will introduce basic spatial analytic functionalities using open source tools, mainly in R, using applied examples for visualizing, mapping, and understanding the opioid risk environment. For this tutorial, you’ll need to have R and RStudio downloaded and installed on your system. You should be able to install packages, and have very basic familiarity with R following intro-level tutorials provided through installation guides. You can also refer to this R for Social Scientists tutorial developed by Data Carpentry for a refresher. You should also know how to find the address to a folder on your computer system. We will work with following libraries, so please be sure to install: * sf * tmap * tidyverse * tidycensus Note: You may find another library called “sp” if you google search spatial analysis in R. Note that sp and sf are two different packages. If you are familiar with sp, see this guide for a translation of sp to sf commands. Please reach out to Marynia Kolak at mkolak@uchicago.edu to learn more about the Opioid Environment program at the Center for Spatial Data Science, or with any questions about the resources on this site. "],
["spatial-data-introduction.html", "Spatial Data Introduction What is spatial data? Vector data and shapefile Coordiante Reference System Contributors and Further Resources", " Spatial Data Introduction UNDER CONSTRUCTION What is spatial data? Spatial data refers to data that contain information about specific locations, and the information content of the data may change with location. In other words, “information” and “location” are two important elements in spatial data. In some occassions, spatial data may only include “location.” But without “location,” the data is no longer spatial anymore. For example, a spatial data that describes the resource distribution of Medications for Opioid Overuse Disorder (MOUDs) must contain location information of these MOUD resources, otherwise the data becomes a non-spatial list of those resources. For the purpose of this tutorial, we will only briefly introduce some important concept in spatial data. See Further Resources if you would like to learn more about these concepts. Vector data and shapefile Two common formats of spatial data are vector and raster data. For the purpose of this tutorial, we will focus on vector data that represents the world surface using points, lines, and polygons. Connecting points can generate lines, and connecting lines that crate an enclosed area can generate polygons. Vector data can come in a variety of different formats, among which the most commonly known is shapefile. The shapefile format consists of a collection of files with a common prefix, stored in the same directory. Three mandary files have filename extensions .shp, .shx, and .dbf. In many scenarios, these files are compressed into one file (such as .zip and .tar.gz). Coordiante Reference System As noted before, the most fundamental element of a spatial data is “location.” Coordinate reference system (CRS) tells your mapping software (such as R) what method should be used to flatten or project the Earth’s surface onto a 2-dimensional map. Because different CRS implies different ways of projections and generates substantially different visualizations, it is important to make sure the CRS accompanied with each spatial data are the same before implementing any spatial joining practices. In sf, you can use the function st_crs to check the CRS used in one data, and the function st_transform to project the data to a particular CRS. See this Interactive Tutorial that demonstrates these functions. Contributors and Further Resources Further resources See Chapter 2 Geographic data in R in Geocomputation with R for more info about Vector data, Raster data, and Coordiante Reference Systems. See this Software Carpentry workshop for more explanations to better understand coordinate reference systems. See this Interactive Tutorial that uses sf package to project spatial data in R. Contributors Qinyun Lin, University of Chicago is the principal author of the initial version of this tutorial. Helpful improvements provided by Marynia Kolak and Moksha Menghaney. Email: qinyunlin@uchicago for any issues/comments. "],
["geocodingAddress-tutorial.html", "Geocoding and Visualizing Point Data Research Question Environment Setup Read in resource data Geocode addresses Convert to Spatial DataFrame Contributors and Further Resources", " Geocoding and Visualizing Point Data Research Question One of the major goals for our research group is to calculate and compare access to different Medications for Opioid Overuse Disorder (MOUDs). But before one can run any analytics on the resource location data, we need to convert resource addresses to spatial data points, which can be then used to calculate access metrics. Geocoding is the formal process of converting addresses (like a street address) into geographic coordinates (latitude and longitude). In this tutorial we demonstrate how to geocode a bunch of addresses to spatial data points that can be then used for mapping and other geospatial analysis. Environment Setup To replicate the code &amp; functions illustrated in this tutorial, you’ll need to have R and RStudio downloaded and installed on your system. This tutorial assumes some familiarity with the R programming language. Packages used We will use the following packages in this tutorial: sf: to manipulate spatial data tmap: to visualize and create maps tidygeocoder: to convert addresses to geographic coordinates. Required Inputs and Expected Outputs Our inputs will be: a CSV file with the addresses of our resources (“chicago_methadone.csv”) We will convert these addresses to their appropriate geographic coordinates and project them with the relevant crs (coordinate reference system) as spatial data points. Our final result will be a shapefile with the geographic coordinates for each address. Install and load the packages First, let’s install the relevant R packages: install.packages(&quot;sf&quot;) install.packages(&quot;tmap&quot;) install.packages(&quot;tidygeocoder&quot;) Then load the libraries for use. (The message you see about GEOS, GDAL, and PROJ refer to the software libraries that allow you to work with spatial data.) library(sf) library(tidygeocoder) library(tmap) Read in resource data We will use a .csv of methadone clinic addresses in Chicago as an example. Let’s take a look at the first few rows of the dataset. As we can see, our data has only addresses but no geographic coordinates. methadoneClinics &lt;- read.csv(&quot;data/chicago_methadone_nogeometry.csv&quot;) head(methadoneClinics) ## X Name Address City State Zip ## 1 1 Chicago Treatment and Counseling Center, Inc. 4453 North Broadway st. Chicago IL 60640 ## 2 2 Sundace Methadone Treatment Center, LLC 4545 North Broadway St. Chicago IL 60640 ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 4 PDSSC - Chicago, Inc. 2260 N. Elston Ave. Chicago IL 60614 ## 5 5 Center for Addictive Problems, Inc. 609 N. Wells St. Chicago IL 60654 ## 6 6 Family Guidance Centers, Inc. 310 W. Chicago Ave. Chicago IL 60654 Geocode addresses To do any geospatial analysis like mapping and other advanced analysis like spatial joins, we need the latitude and longitude for each location. To get those, there are a number of options in R, we recommend the tidygeocoder package. It uses mutliple geocoding services, providing user with an option to choose. It also provides the option to use cascade method which queries other geocoding services incase the default method fails to provide coordinates. Default method uses the US Census geocoder and this caps you at around 10,000 addresses at once. This process may require some data manipulation, so for your ease you may wish to use a proprietary software instead (i.e. Esri Geocoder, which is included in Esri software like ArcGIS). Here’s an example of geocoding a single address: geo(&quot;4545 North Broadway St. Chicago, IL&quot;, lat = latitude, long = longitude, method = &#39;cascade&#39;) ## # A tibble: 1 x 4 ## address latitude longitude geo_method ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4545 North Broadway St. Chicago, IL 42.0 -87.7 census To apply the function to multiple addresses, follow the next few steps. First we need ensure that we have a character vector of full addresses. str(methadoneClinics) ## &#39;data.frame&#39;: 27 obs. of 6 variables: ## $ X : int 1 2 3 4 5 6 7 8 9 10 ... ## $ Name : chr &quot;Chicago Treatment and Counseling Center, Inc.&quot; &quot;Sundace Methadone Treatment Center, LLC&quot; &quot;Soft Landing Interventions/DBA Symetria Recovery of Lakeview&quot; &quot;PDSSC - Chicago, Inc.&quot; ... ## $ Address: chr &quot;4453 North Broadway st.&quot; &quot;4545 North Broadway St.&quot; &quot;3934 N. Lincoln Ave.&quot; &quot;2260 N. Elston Ave.&quot; ... ## $ City : chr &quot;Chicago&quot; &quot;Chicago&quot; &quot;Chicago&quot; &quot;Chicago&quot; ... ## $ State : chr &quot;IL&quot; &quot;IL&quot; &quot;IL&quot; &quot;IL&quot; ... ## $ Zip : int 60640 60640 60613 60614 60654 60654 60651 60607 60607 60616 ... # convert all fields to character first to avoid issues with factors methadoneClinics$fullAdd &lt;- paste(as.character(methadoneClinics$Address), as.character(methadoneClinics$City), as.character(methadoneClinics$State), as.character(methadoneClinics$Zip)) head(methadoneClinics) ## X Name Address City State Zip ## 1 1 Chicago Treatment and Counseling Center, Inc. 4453 North Broadway st. Chicago IL 60640 ## 2 2 Sundace Methadone Treatment Center, LLC 4545 North Broadway St. Chicago IL 60640 ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 4 PDSSC - Chicago, Inc. 2260 N. Elston Ave. Chicago IL 60614 ## 5 5 Center for Addictive Problems, Inc. 609 N. Wells St. Chicago IL 60654 ## 6 6 Family Guidance Centers, Inc. 310 W. Chicago Ave. Chicago IL 60654 ## fullAdd ## 1 4453 North Broadway st. Chicago IL 60640 ## 2 4545 North Broadway St. Chicago IL 60640 ## 3 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 2260 N. Elston Ave. Chicago IL 60614 ## 5 609 N. Wells St. Chicago IL 60654 ## 6 310 W. Chicago Ave. Chicago IL 60654 Then geocode the addresses. Tibble below includes the address, latitude, longitude and also the geocoding service used to get the coordinates. Please note geocoding takes a bit of time. geoCodedClinics &lt;- methadoneClinics %&gt;% geocode(methadoneClinics, address = &#39;fullAdd&#39;, lat = latitude, long = longitude, method = &#39;cascade&#39;) geoCodedClinics ## # A tibble: 27 x 10 ## X Name Address City State Zip fullAdd latitude longitude geo_method ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 &quot;Chicago Treatment and Coun… 4453 North Br… Chic… IL 60640 4453 North Broadwa… NA NA osm ## 2 2 &quot;Sundace Methadone Treatmen… 4545 North Br… Chic… IL 60640 4545 North Broadwa… NA NA osm ## 3 3 &quot;Soft Landing Interventions… 3934 N. Linco… Chic… IL 60613 3934 N. Lincoln Av… 42.0 -87.7 census ## 4 4 &quot;PDSSC - Chicago, Inc.&quot; 2260 N. Elsto… Chic… IL 60614 2260 N. Elston Ave… 41.9 -87.7 census ## 5 5 &quot;Center for Addictive Probl… 609 N. Wells … Chic… IL 60654 609 N. Wells St. C… 41.9 -87.6 census ## 6 6 &quot;Family Guidance Centers, I… 310 W. Chicag… Chic… IL 60654 310 W. Chicago Ave… 41.9 -87.6 census ## 7 7 &quot;A Rincon Family Services&quot; 3809 W. Grand… Chic… IL 60651 3809 W. Grand Ave.… 41.9 -87.7 census ## 8 8 &quot;*&quot; 140 N. Ashlan… Chic… IL 60607 140 N. Ashland Ave… 41.9 -87.7 osm ## 9 9 &quot;Healthcare Alternative Sys… 210 N. Ashlan… Chic… IL 60607 210 N. Ashland Ave… 41.9 -87.7 census ## 10 10 &quot;Specialized Assistance Ser… 2630 S. Wabas… Chic… IL 60616 2630 S. Wabash Ave… 41.8 -87.6 census ## # … with 17 more rows The code worked for all addresses except the first two. We already resolved the 4545 North Broadway St.address above but here in the dataframe we get NAs. It is pointing to some issue with the string input. Unfortunately, such quirks are common across geocoding services in R and we just have to handle them. We manually update the full address strings to get apprpriate coordinates. methadoneClinics[1,&#39;fullAdd&#39;] &lt;- &#39;4453 North Broadway St.,Chicago IL 60640&#39; methadoneClinics[2,&#39;fullAdd&#39;] &lt;- &#39;4545 North Broadway St.,Chicago IL 60640&#39; geoCodedClinics &lt;- methadoneClinics %&gt;% geocode(methadoneClinics, address = &#39;fullAdd&#39;, lat = latitude, long = longitude, method = &#39;cascade&#39;) geoCodedClinics ## # A tibble: 27 x 10 ## X Name Address City State Zip fullAdd latitude longitude geo_method ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 &quot;Chicago Treatment and Coun… 4453 North Br… Chic… IL 60640 4453 North Broadwa… 42.0 -87.7 osm ## 2 2 &quot;Sundace Methadone Treatmen… 4545 North Br… Chic… IL 60640 4545 North Broadwa… 42.0 -87.7 osm ## 3 3 &quot;Soft Landing Interventions… 3934 N. Linco… Chic… IL 60613 3934 N. Lincoln Av… 42.0 -87.7 census ## 4 4 &quot;PDSSC - Chicago, Inc.&quot; 2260 N. Elsto… Chic… IL 60614 2260 N. Elston Ave… 41.9 -87.7 census ## 5 5 &quot;Center for Addictive Probl… 609 N. Wells … Chic… IL 60654 609 N. Wells St. C… 41.9 -87.6 census ## 6 6 &quot;Family Guidance Centers, I… 310 W. Chicag… Chic… IL 60654 310 W. Chicago Ave… 41.9 -87.6 census ## 7 7 &quot;A Rincon Family Services&quot; 3809 W. Grand… Chic… IL 60651 3809 W. Grand Ave.… 41.9 -87.7 census ## 8 8 &quot;*&quot; 140 N. Ashlan… Chic… IL 60607 140 N. Ashland Ave… 41.9 -87.7 osm ## 9 9 &quot;Healthcare Alternative Sys… 210 N. Ashlan… Chic… IL 60607 210 N. Ashland Ave… 41.9 -87.7 census ## 10 10 &quot;Specialized Assistance Ser… 2630 S. Wabas… Chic… IL 60616 2630 S. Wabash Ave… 41.8 -87.6 census ## # … with 17 more rows Convert to Spatial DataFrame Next we convert our dataframe to a spatial data frame using the st_as_sf() function. The coords argument specifies which two columns are the X and Y for your data. We set the crs argument equal to 4326 because this data is in latitude and longitude (otherwise known as “unprojected”, which means it is not in feet or meters). Please note longitude is entered as first column rather than the latitude. It is a very common mistake. methadoneSf &lt;- st_as_sf(geoCodedClinics, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) head(data.frame(methadoneSf)) ## X Name Address City State Zip ## 1 1 Chicago Treatment and Counseling Center, Inc. 4453 North Broadway st. Chicago IL 60640 ## 2 2 Sundace Methadone Treatment Center, LLC 4545 North Broadway St. Chicago IL 60640 ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 4 PDSSC - Chicago, Inc. 2260 N. Elston Ave. Chicago IL 60614 ## 5 5 Center for Addictive Problems, Inc. 609 N. Wells St. Chicago IL 60654 ## 6 6 Family Guidance Centers, Inc. 310 W. Chicago Ave. Chicago IL 60654 ## fullAdd geo_method geometry ## 1 4453 North Broadway St.,Chicago IL 60640 osm POINT (-87.65566 41.96321) ## 2 4545 North Broadway St.,Chicago IL 60640 osm POINT (-87.65694 41.96475) ## 3 3934 N. Lincoln Ave. Chicago IL 60613 census POINT (-87.67818 41.95331) ## 4 2260 N. Elston Ave. Chicago IL 60614 census POINT (-87.67407 41.92269) ## 5 609 N. Wells St. Chicago IL 60654 census POINT (-87.63409 41.89268) ## 6 310 W. Chicago Ave. Chicago IL 60654 census POINT (-87.63636 41.89657) Note that this is a data frame, but that it has a final column called “geometry” that stores the spatial information. We can now plot the location of the methadone clinics with base R. tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(methadoneSf) + tm_dots() + tm_basemap(&quot;OpenStreetMap&quot;) Finally, we save this spatial dataframe as a shapefile which can be used for further spatial analysis. write_sf(methadoneSf, &quot;methadoneClinics.shp&quot;) Contributors and Further Resources Contributors Moksha Menghaney, University of Chicago is the principal author of the initial version of this tutorial. Helpful improvements provided by Marynia Kolak. Email: mmenghaney@uchicago.edu for any issues/comments. "],
["centroid-access-tutorial.html", "Calculate Minimum Distance Access Metric Research Question Environment Setup Read in resource data Read in zip code data Calculate centroids of zip code boundaries Ensure that centroid and resource projections match Calculate distance from centroid to nearest resource Save as zip-code level dataset Contributors and Further Resources", " Calculate Minimum Distance Access Metric Research Question Spatial Access to specific resource is often considered a multidimensional concept where accessibility can be measured on affordability, availability, accommodation &amp; acceptability [include reference]. Distance to the nearest resource is a common metric used to capture the availability of a resource, and in this tutorial we demonstrate how to calculate a minimum distance value from a zip code centroid to a set of resources, such as locations of methadone clinics. Each zip code will be assigned a “minimum distance access metric” as a value that indicates access to resources from that zip code. Environment Setup To replicate the codes &amp; functions illustrated in this tutorial, you’ll need to have R and RStudio downloaded and installed on your system. This tutorial assumes some familiarity with the R programming language. Packages used We will use the following packages in this tutorial: sf: to manipulate spatial data tmap: to visualize and create maps units: to convert units within spatial data Required Inputs and Expected Outputs Our inputs will be: a CSV file with the locations of our resources (“chicago_methadone.csv”), and a zip code boundary file (“chicago_zips.shp”). We will calculate the minimum distance between the resources and the centroids of the zip codes, then save the results as a shapefile and as a CSV. Our final result will be a shapefile/CSV with the minimum distance value for each zip. Install and load the packages First, let’s install the relevant R packages: install.packages(&quot;sf&quot;) install.packages(&quot;tmap&quot;) install.packages(&quot;units&quot;) Then load the libraries for use. (The message you see about GEOS, GDAL, and PROJ refer to the software libraries that allow you to work with spatial data.) library(sf) library(tmap) library(units) Read in resource data We will use a CSV of methadone clinic addresses in Chicago as an example. This file represents point locations of clinics. methadone_clinics &lt;- read.csv(&quot;data/chicago_methadone.csv&quot;) Let’s take a look at the first few rows of the dataset. head(methadone_clinics) ## X Name Address City State Zip Longitude ## 1 1 Chicago Treatment and Counseling Center, Inc. 4453 North Broadway st. Chicago IL 60640 -87.65594 ## 2 2 Sundace Methadone Treatment Center, LLC 4545 North Broadway St. Chicago IL 60640 -87.65703 ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview 3934 N. Lincoln Ave. Chicago IL 60613 -87.67844 ## 4 4 PDSSC - Chicago, Inc. 2260 N. Elston Ave. Chicago IL 60614 -87.67412 ## 5 5 Center for Addictive Problems, Inc. 609 N. Wells St. Chicago IL 60654 -87.63406 ## 6 6 Family Guidance Centers, Inc. 310 W. Chicago Ave. Chicago IL 60654 -87.63635 ## Latitude ## 1 41.96303 ## 2 41.96481 ## 3 41.95321 ## 4 41.92272 ## 5 41.89273 ## 6 41.89660 Our data has been geocoded, which means that it has latitude and longitude as columns associated with the address in the data. If you do not have this information, check the Geocoding and Visualizing Point Data to geocode your data. Next we convert the dataframe of addresses to a spatial data frame using the st_as_sf() function. The coords argument specifies which two columns are the X and Y for your data. We set the crs argument equal to 4326 because this data is in latitude and longitude (otherwise known as “unprojected”, which means it is not in feet or meters). meth_sf &lt;- st_as_sf(methadone_clinics, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) meth_sf ## Simple feature collection with 27 features and 6 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: -87.73491 ymin: 41.68699 xmax: -87.57656 ymax: 41.96481 ## geographic CRS: WGS 84 ## First 10 features: ## X Name Address City State Zip ## 1 1 Chicago Treatment and Counseling Center, Inc. 4453 North Broadway st. Chicago IL 60640 ## 2 2 Sundace Methadone Treatment Center, LLC 4545 North Broadway St. Chicago IL 60640 ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 4 PDSSC - Chicago, Inc. 2260 N. Elston Ave. Chicago IL 60614 ## 5 5 Center for Addictive Problems, Inc. 609 N. Wells St. Chicago IL 60654 ## 6 6 Family Guidance Centers, Inc. 310 W. Chicago Ave. Chicago IL 60654 ## 7 7 A Rincon Family Services 3809 W. Grand Ave. Chicago IL 60651 ## 8 8 * 140 N. Ashland Ave. Chicago IL 60607 ## 9 9 Healthcare Alternative Systems, Inc./NEXA 210 N. Ashland Ave. Chicago IL 60607 ## 10 10 Specialized Assistance Services, NFP 2630 S. Wabash Ave. Chicago IL 60616 ## geometry ## 1 POINT (-87.65594 41.96303) ## 2 POINT (-87.65703 41.96481) ## 3 POINT (-87.67844 41.95321) ## 4 POINT (-87.67412 41.92272) ## 5 POINT (-87.63406 41.89273) ## 6 POINT (-87.63635 41.8966) ## 7 POINT (-87.72196 41.90436) ## 8 POINT (-87.66694 41.8847) ## 9 POINT (-87.667 41.88561) ## 10 POINT (-87.6253 41.84459) Note that this is a data frame, but that it has a final column called “geometry” that stores the spatial information. We can now plot the location of the methadone clinics with base R. We use the st_geometry() function to just get a single point map from the geographies. plot(st_geometry(meth_sf)) To make a slightly more interesting map, you can add an interactive basemap with tmap, using the tmap_mode function to change to “view” mode: tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(meth_sf) + tm_dots() Read in zip code data If you have zip code boundary data from the Census (or other relevant site), you can load them into R with the read_sf command. Boundary data is commonly stored in the shapefile format, which has both a spatial (.shp, .shx, .prj) and a flat-file (.dbf) component. Shapefiles are made of four files (.shp, .shx, .prj, .dbf), all which needed to be in the same folder for the file to be read. chicago_zips &lt;- read_sf(&quot;data/chicago_zips.shp&quot;) Note: If you do not have the zip boundary data, please see the Get Geometry from [Downloading Community Contextual Data] (#contextual-data) for instructions on how to pull them directly from the Census website into R. If we take a look at the top of the data, we can see that the zip codes have data attached to them. The last column is the “geometry” column, which stores the spatial data. Additionally, there is a header with some spatial metadata about the data frame, including the type of geometry (“MULTIPOLYGON”), the bounding box (the square that surrounds your data), and the geographic projection (4326 is the shortcode reference for the string that starts “+proj=longlat +datum=WGS84 +no_defs”). Otherwise, this is just like your normal R tabular data frame. head(chicago_zips) ## Simple feature collection with 6 features and 9 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -88.06058 ymin: 41.73452 xmax: -87.58209 ymax: 42.04052 ## geographic CRS: WGS 84 ## # A tibble: 6 x 10 ## ZCTA5CE10 GEOID10 CLASSFP10 MTFCC10 FUNCSTAT10 ALAND10 AWATER10 INTPTLAT10 INTPTLON10 geometry ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;MULTIPOLYGON [°]&gt; ## 1 60501 60501 B5 G6350 S 12532295 974360 +41.78022… -087.8232… (((-87.86289 41.7544, -87.8624… ## 2 60007 60007 B5 G6350 S 36493383 917560 +42.00860… -087.9973… (((-88.06058 41.9997, -88.0605… ## 3 60651 60651 B5 G6350 S 9052862 0 +41.90209… -087.7408… (((-87.77559 41.90875, -87.774… ## 4 60652 60652 B5 G6350 S 12987857 0 +41.74793… -087.7147… (((-87.74205 41.77113, -87.741… ## 5 60653 60653 B5 G6350 S 6041418 1696670 +41.81996… -087.6059… (((-87.62623 41.81469, -87.625… ## 6 60654 60654 B5 G6350 S 1464813 113471 +41.89182… -087.6383… (((-87.64775 41.8964, -87.6476… We can check that we pulled the zip code data properly by plotting it. Again, we use the st_geometry() function to just get the outline of the geometries. plot(st_geometry(chicago_zips)) We can add a second layer in blue with the access locations: plot(st_geometry(chicago_zips)) plot(st_geometry(meth_sf), col = &quot;blue&quot;, add = TRUE) With multiple layers, it can be easier to use tmap to plot: tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting tm_shape(chicago_zips) + tm_borders() + tm_shape(meth_sf) + tm_dots(col = &quot;blue&quot;, size = 0.2) Again, we can create an interactive map with tmap: tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(chicago_zips) + tm_borders() + tm_shape(meth_sf) + tm_dots() Calculate centroids of zip code boundaries Now, we will calculate the centroids of the zip code boundaries. We will first need to project our data, which means change it from latitude and longitude to meaningful units, like ft or meters, so we can calculate distance properly. We’ll use the Illinois State Plane projection, with an EPSG code of 3435. Aside: To find the most appropriate projection for your data, do a Google Search for which projection works well - for state level data, each state has a State Plane projection with a specific code, known as the EPSG. I use epsg.io to check projections - here’s the New York State Plane page. Use the st_transform function to change the projection of the data. Notice how the values in geometry go from being relatively small (unprojected, lat/long) to very large (projected, in US feet). chicago_zips &lt;- st_transform(chicago_zips, 3435) chicago_zips ## Simple feature collection with 85 features and 9 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 1058388 ymin: 1791133 xmax: 1205317 ymax: 1966816 ## projected CRS: NAD83 / Illinois East (ftUS) ## # A tibble: 85 x 10 ## ZCTA5CE10 GEOID10 CLASSFP10 MTFCC10 FUNCSTAT10 ALAND10 AWATER10 INTPTLAT10 INTPTLON10 geometry ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;MULTIPOLYGON [US_survey_foot&gt; ## 1 60501 60501 B5 G6350 S 12532295 974360 +41.78022… -087.8232… (((1112613 1853447, 1112726 1… ## 2 60007 60007 B5 G6350 S 36493383 917560 +42.00860… -087.9973… (((1058389 1942598, 1058390 1… ## 3 60651 60651 B5 G6350 S 9052862 0 +41.90209… -087.7408… (((1136069 1909833, 1136235 1… ## 4 60652 60652 B5 G6350 S 12987857 0 +41.74793… -087.7147… (((1145542 1859745, 1145607 1… ## 5 60653 60653 B5 G6350 S 6041418 1696670 +41.81996… -087.6059… (((1177007 1875855, 1177096 1… ## 6 60654 60654 B5 G6350 S 1464813 113471 +41.89182… -087.6383… (((1170904 1905583, 1170932 1… ## 7 60655 60655 B5 G6350 S 11408010 0 +41.69477… -087.7037… (((1146378 1830511, 1146444 1… ## 8 60656 60656 B5 G6350 S 8465226 0 +41.97428… -087.8271… (((1110359 1933204, 1110389 1… ## 9 60657 60657 B5 G6350 S 5888324 2025836 +41.94029… -087.6468… (((1162394 1923242, 1162526 1… ## 10 60659 60659 B5 G6350 S 5251086 2818 +41.99148… -087.7039… (((1148555 1941516, 1148713 1… ## # … with 75 more rows Then, we will calculate the centroids: chicago_centroids &lt;- st_centroid(chicago_zips) ## Warning in st_centroid.sf(chicago_zips): st_centroid assumes attributes are constant over geometries of x chicago_centroids ## Simple feature collection with 85 features and 9 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 1076716 ymin: 1802621 xmax: 1198093 ymax: 1956017 ## projected CRS: NAD83 / Illinois East (ftUS) ## # A tibble: 85 x 10 ## ZCTA5CE10 GEOID10 CLASSFP10 MTFCC10 FUNCSTAT10 ALAND10 AWATER10 INTPTLAT10 INTPTLON10 geometry ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;POINT [US_survey_foot]&gt; ## 1 60501 60501 B5 G6350 S 12532295 974360 +41.7802209 -087.8232440 (1123181 1862885) ## 2 60007 60007 B5 G6350 S 36493383 917560 +42.0086000 -087.9973398 (1076716 1945541) ## 3 60651 60651 B5 G6350 S 9052862 0 +41.9020934 -087.7408565 (1145540 1907470) ## 4 60652 60652 B5 G6350 S 12987857 0 +41.7479319 -087.7147951 (1153039 1851344) ## 5 60653 60653 B5 G6350 S 6041418 1696670 +41.8199645 -087.6059654 (1182494 1877789) ## 6 60654 60654 B5 G6350 S 1464813 113471 +41.8918225 -087.6383036 (1173771 1904104) ## 7 60655 60655 B5 G6350 S 11408010 0 +41.6947762 -087.7037764 (1156187 1831997) ## 8 60656 60656 B5 G6350 S 8465226 0 +41.9742800 -087.8271283 (1121899 1933624) ## 9 60657 60657 B5 G6350 S 5888324 2025836 +41.9402931 -087.6468569 (1170365 1921589) ## 10 60659 60659 B5 G6350 S 5251086 2818 +41.9914885 -087.7039859 (1155320 1939992) ## # … with 75 more rows For each zip code, this will calculate the centroid, and the output will be a point dataset. Plot to double check that everything is ok. The st_geometry() function will once again just return the outline: plot(st_geometry(chicago_zips)) plot(st_geometry(chicago_centroids), add = TRUE, col = &quot;red&quot;) Once again, we can create an interactive map: tm_shape(chicago_zips) + tm_borders() + tm_shape(chicago_centroids) + tm_dots() Ensure that centroid and resource projections match If we immediately try to calculate the distance between the zip centroids and the locations of the resources using the st_distance function, we’ll get an error: st_distance(chicago_centroids, meth_sf, by_element = TRUE) Error in st_distance(chicago_centroids, meth_sf, by_element = TRUE) : st_crs(x) == st_crs(y) is not TRUE Why is there an error? Because the projection of the centroids and the resource locations don’t match up. Let’s project the resource locations so that they match the projection of the centroids. First, use the st_crs function to check that the coordinate reference system (or projection) is the same. They’re not, so we have to fix it. st_crs(chicago_centroids) ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCRS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;SPCS83 Illinois East zone (US Survey feet)&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,36.6666666666667, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-88.3333333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.999975, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,984250, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;USA - Illinois - SPCS - E&quot;], ## BBOX[37.06,-89.28,42.5,-87.02]], ## ID[&quot;EPSG&quot;,3435]] st_crs(meth_sf) ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic latitude (Lat)&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic longitude (Lon)&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;World&quot;], ## BBOX[-90,-180,90,180]], ## ID[&quot;EPSG&quot;,4326]] We’ll take the CRS from the zip code centroids data, and use it as input to st_transform applied to the methadone clinics data. new_crs &lt;- st_crs(chicago_centroids) new_crs ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCRS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;SPCS83 Illinois East zone (US Survey feet)&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,36.6666666666667, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-88.3333333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.999975, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,984250, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;USA - Illinois - SPCS - E&quot;], ## BBOX[37.06,-89.28,42.5,-87.02]], ## ID[&quot;EPSG&quot;,3435]] meth_sf &lt;- st_transform(meth_sf, new_crs) If we check the CRS again, we now see that they match. Mismatched projections are a commonly made mistake in geospatial data processing. st_crs(chicago_centroids) ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCRS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;SPCS83 Illinois East zone (US Survey feet)&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,36.6666666666667, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-88.3333333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.999975, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,984250, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;USA - Illinois - SPCS - E&quot;], ## BBOX[37.06,-89.28,42.5,-87.02]], ## ID[&quot;EPSG&quot;,3435]] st_crs(meth_sf) ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCRS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;SPCS83 Illinois East zone (US Survey feet)&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,36.6666666666667, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-88.3333333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.999975, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,984250, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;USA - Illinois - SPCS - E&quot;], ## BBOX[37.06,-89.28,42.5,-87.02]], ## ID[&quot;EPSG&quot;,3435]] Now we have the zip boundaries, the centroids of the zips, and the resource locations, as shown below. Next, we will calculate the distance to the nearest resource from each zip code centroid. plot(st_geometry(chicago_zips)) plot(st_geometry(chicago_centroids), col = &quot;red&quot;, add = TRUE) plot(st_geometry(meth_sf), col = &quot;blue&quot;, add = TRUE) Calculate distance from centroid to nearest resource First, we’ll identify the resource that is the closest to a zip centroid using the st_nearest_feature function. (It will return the index of the object that is nearest, so we will subset the resources by the index to get the nearest object.) nearest_clinic_indexes &lt;- st_nearest_feature(chicago_centroids, meth_sf) nearest_clinic &lt;- meth_sf[nearest_clinic_indexes,] nearest_clinic ## Simple feature collection with 85 features and 6 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 1147259 ymin: 1829334 xmax: 1190725 ymax: 1930492 ## projected CRS: NAD83 / Illinois East (ftUS) ## First 10 features: ## X Name Address City State Zip ## 16 16 Katherine Boone Robinson Foundation 4100 W. Ogden Ave. Chicago IL 60623 ## 7 7 A Rincon Family Services 3809 W. Grand Ave. Chicago IL 60651 ## 7.1 7 A Rincon Family Services 3809 W. Grand Ave. Chicago IL 60651 ## 26 26 New Hope Community Service Center 2559 W. 79th St. Chicago IL 60652 ## 15 15 HRDI- Grand Boulevard Professional Counseling Center 340 E. 51st St. Chicago IL 60615 ## 5 5 Center for Addictive Problems, Inc. 609 N. Wells St. Chicago IL 60654 ## 26.1 26 New Hope Community Service Center 2559 W. 79th St. Chicago IL 60652 ## 7.2 7 A Rincon Family Services 3809 W. Grand Ave. Chicago IL 60651 ## 1 1 Chicago Treatment and Counseling Center, Inc. 4453 North Broadway st. Chicago IL 60640 ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview 3934 N. Lincoln Ave. Chicago IL 60613 ## geometry ## 16 POINT (1149563 1888684) ## 7 POINT (1150678 1908331) ## 7.1 POINT (1150678 1908331) ## 26 POINT (1160443 1852136) ## 15 POINT (1179400 1871296) ## 5 POINT (1174640 1904278) ## 26.1 POINT (1160443 1852136) ## 7.2 POINT (1150678 1908331) ## 1 POINT (1168480 1929847) ## 3 POINT (1162389 1926221) Then, we will calculate the distance between the nearest resource and the zip code centroid with the st_distance function. As shown above, make sure both of your datasets are projected, and in the same projection, before you run st_distance. min_dists &lt;- st_distance(chicago_centroids, nearest_clinic, by_element = TRUE) min_dists ## Units: [US_survey_foot] ## [1] 36899.7187 82794.9499 5210.0088 7446.1648 7192.4268 885.6142 20584.4913 38314.4490 8469.9351 15479.7403 ## [11] 9796.8522 4469.3071 33683.4980 24082.8186 24169.2397 45189.1792 31267.0776 10254.9649 10958.9389 13821.3363 ## [21] 49825.9391 32430.5115 36620.8289 22036.8980 13688.1510 22177.9153 63240.9022 4249.2975 3766.8707 5131.5781 ## [31] 5548.8181 8889.3859 3988.0292 5492.6866 7091.5663 6849.3251 3958.0982 45915.8759 32569.9607 44521.9752 ## [41] 58458.5465 5406.8794 5887.8101 2278.0342 6660.2051 5735.8249 304.8631 13604.9478 6942.3909 4993.9155 ## [51] 2841.4986 1679.0098 7651.3608 2529.0080 1667.5299 9406.8277 16622.9728 2042.7828 11421.7437 22480.9662 ## [61] 12104.7974 7613.8768 39613.5103 11724.1443 18463.5889 27529.9719 5232.8529 8774.4241 25352.7928 18954.0196 ## [71] 26416.7824 7550.1810 3455.8152 10997.6485 3097.7944 16812.6822 6171.7070 25247.7440 17149.4029 15235.8434 ## [81] 25019.9566 18574.8897 20179.9325 33065.4125 22450.6644 This is in US feet. To change to a more meaningful unit, such as miles, we can use the set_units() function: min_dists_mi &lt;- set_units(min_dists, &quot;mi&quot;) min_dists_mi ## Units: [mi] ## [1] 6.98859707 15.68089308 0.98674606 1.41026130 1.36220476 0.16773030 3.89858569 7.25653895 1.60415759 ## [10] 2.93177485 1.85546815 0.84646137 6.37946314 4.56114901 4.57751667 8.55857378 5.92180684 1.94223208 ## [19] 2.07556077 2.61768256 9.43674977 6.14215462 6.93577693 4.17366328 2.59245803 4.20037114 11.97746755 ## [28] 0.80479280 0.71342392 0.97189174 1.05091463 1.68359919 0.75531008 1.04028363 1.34310236 1.29722327 ## [37] 0.74964130 8.69620601 6.16856550 8.43220914 11.07171655 1.02403224 1.11511778 0.43144674 1.26140501 ## [46] 1.08633265 0.05773933 2.57669981 1.31484938 0.94581922 0.53816370 0.31799492 1.44912426 0.47897974 ## [55] 0.31582069 1.78159972 3.14829660 0.38689146 2.16321335 4.25776726 2.29257984 1.44202501 7.50257377 ## [64] 2.22048632 3.49689882 5.21402025 0.99107260 1.66182607 4.80167491 3.58978362 5.00318849 1.42996139 ## [73] 0.65451176 2.08289214 0.58670466 3.18422648 1.16888624 4.78177925 3.24799947 2.88558217 4.73863762 ## [82] 3.51797856 3.82196456 6.26240125 4.25202828 We then rejoin the minimum distances to the zip code data, by column binding min_dists_mi to the original chicago_zips data. min_dist_sf &lt;- cbind(chicago_zips, min_dists_mi) min_dist_sf ## Simple feature collection with 85 features and 10 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 1058388 ymin: 1791133 xmax: 1205317 ymax: 1966816 ## projected CRS: NAD83 / Illinois East (ftUS) ## First 10 features: ## ZCTA5CE10 GEOID10 CLASSFP10 MTFCC10 FUNCSTAT10 ALAND10 AWATER10 INTPTLAT10 INTPTLON10 min_dists_mi ## 1 60501 60501 B5 G6350 S 12532295 974360 +41.7802209 -087.8232440 6.9885971 [mi] ## 2 60007 60007 B5 G6350 S 36493383 917560 +42.0086000 -087.9973398 15.6808931 [mi] ## 3 60651 60651 B5 G6350 S 9052862 0 +41.9020934 -087.7408565 0.9867461 [mi] ## 4 60652 60652 B5 G6350 S 12987857 0 +41.7479319 -087.7147951 1.4102613 [mi] ## 5 60653 60653 B5 G6350 S 6041418 1696670 +41.8199645 -087.6059654 1.3622048 [mi] ## 6 60654 60654 B5 G6350 S 1464813 113471 +41.8918225 -087.6383036 0.1677303 [mi] ## 7 60655 60655 B5 G6350 S 11408010 0 +41.6947762 -087.7037764 3.8985857 [mi] ## 8 60656 60656 B5 G6350 S 8465226 0 +41.9742800 -087.8271283 7.2565390 [mi] ## 9 60657 60657 B5 G6350 S 5888324 2025836 +41.9402931 -087.6468569 1.6041576 [mi] ## 10 60659 60659 B5 G6350 S 5251086 2818 +41.9914885 -087.7039859 2.9317749 [mi] ## geometry ## 1 MULTIPOLYGON (((1112613 185... ## 2 MULTIPOLYGON (((1058389 194... ## 3 MULTIPOLYGON (((1136069 190... ## 4 MULTIPOLYGON (((1145542 185... ## 5 MULTIPOLYGON (((1177007 187... ## 6 MULTIPOLYGON (((1170904 190... ## 7 MULTIPOLYGON (((1146378 183... ## 8 MULTIPOLYGON (((1110359 193... ## 9 MULTIPOLYGON (((1162394 192... ## 10 MULTIPOLYGON (((1148555 194... We can now visualize the zip-level access to methadone clinics using our new access metric, using the tmap package. tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting tm_shape(min_dist_sf) + tm_polygons(&quot;min_dists_mi&quot;, title = &quot;Minimum Distance (mi)&quot;) + tm_layout(main.title = &quot;Minimum Distance from Zip Centroid\\n to Methadone Clinic&quot;, main.title.position = &quot;center&quot;, main.title.size = 1) Access by zip code can also be combined with locations of resources: tm_shape(min_dist_sf) + tm_polygons(&quot;min_dists_mi&quot;, title = &quot;Minimum Distance (mi)&quot;) + tm_shape(meth_sf) + tm_dots(size = 0.2) + tm_layout(main.title = &quot;Minimum Distance from Zip Centroid\\n to Methadone Clinic&quot;, main.title.position = &quot;center&quot;, main.title.size = 1) Save as zip-code level dataset To save our final result to a CSV, use the layer_options = &quot;GEOMETRY=AS_XY&quot; command. Note that this option only works when you are working with point data. write_sf(min_dist_sf, &quot;min_dist.csv&quot;, layer_options = &quot;GEOMETRY=AS_XY&quot;) We can also write out this data to a shapefile format: write_sf(min_dist_sf, &quot;min_dists_sf.shp&quot;) Contributors and Further Resources Contributors Angela Li, University of Chicago is the principal author of the initial version of this tutorial. Helpful improvements provided by Moksha Menghaney and Marynia Kolak. Email: mmenghaney@uchicago.edu for any issues/comments. "],
["getACSData-tutorial.html", "Downloading Community Contextual Data Research Question Environment Setup Get your Census API Key Download variables of interest Get Geometry Appendix", " Downloading Community Contextual Data Research Question Once we identify the appropriate access metric to use, we can now include contextual data to add nuance to our findings. This can help identify if any specific disparities in access exist for certain groups of people or if there are any specific factors that can help explain the spatial patterns. Such datasets are often sourced from the US Census Bureau. The American Community Survey (ACS) is an ongoing survey that provides data every year with 1 and 5-year estimates. We generally recommend using the 5-year estimates as these multiperiod estimates tend to have increased statistical reliability as compared to the 1-year numbers, especially for less populated areas and small population subgroups. In this tutorial we demonstrate how to explore and download most commonly used population datasets from the same, with and without spatial components. Please note this tutorial focuses only on the American Community Survey datasets available via the Census Bureau API. Environment Setup To replicate the codes &amp; functions illustrated in this tutorial, you’ll need to have R and RStudio downloaded and installed on your system. This tutorial assumes some familiarity with the R programming language. Packages used We will use the following packages: sf: to read/write sf (spatial) objects tidycensus: to download census variables using ACS API tidyverse: to manipulate and clean data tigris : to download census tiger shapefiles Required Inputs and Expected Outputs We will not be using an external input for this exercise. Our output will be a .csv file and shapefile (.shp suite) with race data at the census tract level. Install and load the packages First, let’s install the relevant R packages: install.packages(&quot;sf&quot;) install.packages(&quot;tidycensus&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;tigris&quot;) install.packages(&quot;tidycensus&quot;) library(sf) library(tidycensus) library(tidyverse) library(tigris) Get your Census API Key To be able to use the Census API, we need to signup for an API key. This key effectively is a string identifier for the server to communicate with your machine. A key can be obtained using an email from here. Once we get the key, we can install it by running the code below. census_api_key(&quot;yourkeyhere&quot;, install = TRUE) # installs the key for future sessions. In instances where we might not want to save our key in the .Renviron - for example, when using a shared computer, we can always reinstall the same key using the code above but with install = FALSE. To check an already installed census API key, run Sys.getenv(&quot;CENSUS_API_KEY&quot;) Download variables of interest We can now start using the tidycensus package to download population based datasets from the US Census Bureau. In this tutorial, we will be covering methods to download data at the state, county, zip and census tract levels. We will also be covering methods to download the data with and without the geometry feature of the geographic entities. To download a particular variable or table using tidycensus, we need the relevant variable ID, which one can check by reviewing the variables available via load_variables() function. For details on exploring the variables available via the tidycensus &amp; to get their identifiers, check the Explore variables available section in Appendix. We can now download the variables using get_acs() function. Given ACS data is based of an annual sample, the datapoints are available as an estimate with a margin or error (moe). The package provides both values for any requested variable in the tidy format. For the examples covered in this tutorial, the 4 main inputs for get_acs() function are: geography - for what scale to source the data for (state / county / tract / zcta) variables - character string or a vector of character strings of variable IDs to source year - the year to source the data for geometry - whether or not to include the geometry feature in the tibble. (TRUE / FALSE) State Level To get data for only a specific state, we can add state = sampleStateName. stateDf &lt;- get_acs(geography = &#39;state&#39;, variables = c(totPop18 = &quot;B01001_001&quot;, hispanic =&quot;B03003_003&quot;, notHispanic = &quot;B03003_002&quot;, white = &quot;B02001_002&quot;, afrAm = &quot;B02001_003&quot;, asian = &quot;B02001_005&quot;), year = 2018, geometry = FALSE) head(stateDf) ## # A tibble: 6 x 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama totPop18 4864680 NA ## 2 01 Alabama white 3317453 3345 ## 3 01 Alabama afrAm 1293186 2745 ## 4 01 Alabama asian 64609 1251 ## 5 01 Alabama notHispanic 4661534 393 ## 6 01 Alabama hispanic 203146 393 As we can see the data is available in the tidy format. We can use other tools in the tidyverse universe to clean and manipulate it. stateDf &lt;- stateDf %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) %&gt;% mutate(hispPr18 = hispanic/totPop18, WhitePr18 = white/totPop18, AfrAmPr18 = afrAm/totPop18, AsianPr18 = asian/totPop18) %&gt;% select(GEOID,totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) head(stateDf) ## # A tibble: 6 x 6 ## GEOID totPop18 hispPr18 WhitePr18 AfrAmPr18 AsianPr18 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 4864680 0.0418 0.682 0.266 0.0133 ## 2 02 738516 0.0693 0.648 0.0327 0.0630 ## 3 04 6946685 0.311 0.772 0.0439 0.0329 ## 4 05 2990671 0.0732 0.770 0.154 0.0147 ## 5 06 39148760 0.389 0.601 0.0579 0.143 ## 6 08 5531141 0.214 0.842 0.0412 0.0312 County Level Similarly, for county level use geometry = county to download for all counties in the U.S. use geometry = county, state = sampleStateName for all counties within a state use geometry = county, state = sampleStateName, county = sampleCountyName for a specific county We can also use the FIPS codes for the relevant state &amp; counties. Finally, we can also write the tibble to a .csv file. countyDf &lt;- get_acs(geography = &#39;county&#39;, variables = c(totPop18 = &quot;B01001_001&quot;, hispanic =&quot;B03003_003&quot;, notHispanic = &quot;B03003_002&quot;, white = &quot;B02001_002&quot;, afrAm = &quot;B02001_003&quot;, asian = &quot;B02001_005&quot;), year = 2018, state = &#39;IL&#39;, geometry = FALSE) %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) %&gt;% mutate(hispPr18 = hispanic/totPop18, WhitePr18 = white/totPop18, AfrAmPr18 = afrAm/totPop18, AsianPr18 = asian/totPop18) %&gt;% select(GEOID,totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) head(countyDf) ## # A tibble: 6 x 6 ## GEOID totPop18 hispPr18 WhitePr18 AfrAmPr18 AsianPr18 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 17001 66427 0.0154 0.931 0.0408 0.00813 ## 2 17003 6532 0.0112 0.624 0.332 0.000919 ## 3 17005 16712 0.0346 0.909 0.0624 0.0117 ## 4 17007 53606 0.214 0.874 0.0222 0.0118 ## 5 17009 6675 0.0428 0.774 0.204 0.00554 ## 6 17011 33381 0.0897 0.936 0.00932 0.00866 write.csv(countyDf , file = &quot;IL_County_18.csv&quot;) Zipcode Level For zipcode level, use geometry = zcta. Given zips cross state lines, zcta data is only available for the entire U.S. zctaDf &lt;- get_acs(geography = &#39;zcta&#39;,variables = c(totPop18 = &quot;B01001_001&quot;, hispanic =&quot;B03003_003&quot;, notHispanic = &quot;B03003_002&quot;, white = &quot;B02001_002&quot;, afrAm = &quot;B02001_003&quot;, asian = &quot;B02001_005&quot;), year = 2018, geometry = FALSE) %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) %&gt;% mutate(hispPr18 = hispanic/totPop18, WhitePr18 = white/totPop18, AfrAmPr18 = afrAm/totPop18, AsianPr18 = asian/totPop18) %&gt;% select(GEOID,totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) head(zctaDf) ## # A tibble: 6 x 6 ## GEOID totPop18 hispPr18 WhitePr18 AfrAmPr18 AsianPr18 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00601 17242 0.997 0.755 0.00841 0.000174 ## 2 00602 38442 0.935 0.794 0.0278 0 ## 3 00603 48814 0.974 0.765 0.0395 0.00746 ## 4 00606 6437 0.998 0.408 0.0231 0 ## 5 00610 27073 0.962 0.755 0.0257 0 ## 6 00612 60303 0.993 0.807 0.0456 0.00985 dim(zctaDf) ## [1] 33120 6 Census Tract Level For census tract level, at the minimum stateName needs to be provided. use geometry = tract, state = sampleStateName to download all tracts within a state use geometry = tract, state = sampleStateName, county = sampleCountyName to download all tracts within a specific county tractDf &lt;- get_acs(geography = &#39;tract&#39;,variables = c(totPop18 = &quot;B01001_001&quot;, hispanic =&quot;B03003_003&quot;, notHispanic = &quot;B03003_002&quot;, white = &quot;B02001_002&quot;, afrAm = &quot;B02001_003&quot;, asian = &quot;B02001_005&quot;), year = 2018, state = &#39;IL&#39;, geometry = FALSE) %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) %&gt;% mutate(hispPr18 = hispanic/totPop18, WhitePr18 = white/totPop18, AfrAmPr18 = afrAm/totPop18, AsianPr18 = asian/totPop18) %&gt;% select(GEOID,totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) head(tractDf) For more details on the other geographies available via the tidycensus package, check here. Get Geometry Geometry/Geographic Boundaries are one of the key features for American Community Survey Data as they set up the framework for data collection and estimation. While boundaries don’t change often, updates do occur from time to time and census data for a specific year generally tends to use the boundaries available at the beginning of that year. Most ACS products since 2010 reflect the 2010 Census Geographic Definitions. Given certain boundaries like congressional districts, census tracts &amp; block groups are updated after every decennial census, products for year 2009 and earlier will have significantly different boundaries from that in 2010. We recommend using IPUMS datasets to generate estimates for years prior to 2010. The datasets downloaded so far did not have a spatial geometry feature attached to them. To run any spatial analysis on the race data above, we would need to join these dataframes to another spatially-enabled sf object. We can do so by joining on the ‘GEOID’ or any other identifier. We can download the geometry information using two methods : using tigris using tidycensus Using tigris To download and use the Tiger Shapefiles shared by the US Census Bureau we will use the tigris package. Set cb = TRUE to get generalized files, these don’t have high resolution details and hence are smaller in size. yeartoFetch &lt;- 2018 stateShp &lt;- states(year = yeartoFetch, cb = TRUE) countyShp &lt;- counties(year = yeartoFetch, state = &#39;IL&#39;, cb = TRUE) zctaShp &lt;- zctas(year = yeartoFetch, cb = TRUE) tractShp &lt;- tracts(state = &#39;IL&#39;,year = yeartoFetch, cb = TRUE) Now we can merge these geometry files with the race data downloaded in previous section. For states: # check object types &amp; identifier variable type # str(stateShp) # str(stateDf) stateShp &lt;- merge(stateShp, stateDf, by.x = &#39;STATEFP&#39;, by.y = &#39;GEOID&#39;, all.x = TRUE) head(stateShp) Similarly for counties, zctas &amp; census tracts we can use the code below and then finally save the census tract results with geometry in a shapefile using write_sf. countyShp &lt;- merge(countyShp, countyDf, by.x = &#39;GEOID&#39;, by.y = &#39;GEOID&#39;, all.x = TRUE)%&gt;% select(GEOID, STATEFP, COUNTYFP, totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) zctaShp &lt;- merge(zctaShp, zctaDf, by.x = &#39;GEOID10&#39;, by.y = &#39;GEOID&#39;, all.x = TRUE) tractShp &lt;- merge(tractShp, tractDf, by.x = &#39;GEOID&#39;, by.y = &#39;GEOID&#39;, all.x = TRUE) write_sf(countyShp, &quot;IL_County_18.shp&quot;) Using tidycensus The previous method adds an additional step of using tigris package to download the shapefile. The tidycensus package already has the wrapper for invoking tigris within the get_acs() function, and we can simply download the dataset with geometry feature by using geometry = TRUE. The wrapper adds the geometry information to each variable sourced, so the file size can become large in the intermediary steps and slow down the performance, even though the data is in tidy format. In case of large API requests, we recommend downloading the dataset without geometry information and then downloading a nominal variable like total population or percapita income with get geometry using get_acs() or simply using the tigris method, as covered in previous section &amp; then implementing a merge. tractDf &lt;- get_acs(geography = &#39;tract&#39;, variables = c(totPop18 = &quot;B01001_001&quot;, hispanic =&quot;B03003_003&quot;, notHispanic = &quot;B03003_002&quot;, white = &quot;B02001_002&quot;, afrAm = &quot;B02001_003&quot;, asian = &quot;B02001_005&quot;), year = 2018, state = &#39;IL&#39;, geometry = FALSE) %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) %&gt;% mutate(hispPr18 = hispanic/totPop18, WhitePr18 = white/totPop18, AfrAmPr18 = afrAm/totPop18, AsianPr18 = asian/totPop18) %&gt;% select(GEOID,totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) tractShp &lt;- get_acs(geography = &#39;tract&#39;, variables = c(perCapitaIncome = &quot;DP03_0088&quot;), year = 2018, state = &#39;IL&#39;, geometry = TRUE) %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) tractsShp &lt;- merge(tractShp, tractDf, by.x = &#39;GEOID&#39;, by.y = &#39;GEOID&#39;, all.x = TRUE) head(tractShp) Appendix Explore variables available Using tidycensus we can download datasets from various types of tables. The ones most commonly used are: Data Profiles - These are the most commonly used collection of variables grouped by category, e.g. Social (DP02), Economic (DP03), Housing (DP04), Demographic (DP05) Subject Profiles - These generally have more detailed information variables (than DP) grouped by category, e.g. Age &amp; Sex (S0101), Disability Characteristics (S1810) The package also allows access to a suite of B &amp; C tables. We can explore all the variables for our year of interest by running the code below. Please note as the Profiles evolve, variable IDs might change from year to year. sVarnames &lt;- load_variables(2018, &quot;acs5/subject&quot;, cache = TRUE) pVarnames &lt;- load_variables(2018, &quot;acs5/profile&quot;, cache = TRUE) otherVarnames &lt;- load_variables(2018, &quot;acs5&quot;, cache = TRUE) head(pVarnames) ## # A tibble: 6 x 3 ## name label concept ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 DP02_0001 Estimate!!HOUSEHOLDS BY TYPE!!Total households SELECTED SOCIAL CHARACTERISTICS I… ## 2 DP02_000… Percent Estimate!!HOUSEHOLDS BY TYPE!!Total households SELECTED SOCIAL CHARACTERISTICS I… ## 3 DP02_0002 Estimate!!HOUSEHOLDS BY TYPE!!Total households!!Family households (famil… SELECTED SOCIAL CHARACTERISTICS I… ## 4 DP02_000… Percent Estimate!!HOUSEHOLDS BY TYPE!!Total households!!Family household… SELECTED SOCIAL CHARACTERISTICS I… ## 5 DP02_0003 Estimate!!HOUSEHOLDS BY TYPE!!Total households!!Family households (famil… SELECTED SOCIAL CHARACTERISTICS I… ## 6 DP02_000… Percent Estimate!!HOUSEHOLDS BY TYPE!!Total households!!Family household… SELECTED SOCIAL CHARACTERISTICS I… A tibble with table &amp; variable information has three columns : name, label, concept. Name is a combination of table id and variable id within that table. Concept generally identifies the table name or grouping used to arrange variables. Label provides textual details about the variable. We can explore these tibbles to identify the correct variable ID name to use with the get_acs() function by using View(sVarnames) or other filters e.g. for age sVarnames %&gt;% filter(str_detect(concept, &quot;AGE AND SEX&quot;)) %&gt;% # search for this concept filter(str_detect(label, &quot;Under 5 years&quot;)) %&gt;% # search for variables mutate(label = sub(&#39;^Estimate!!&#39;, &#39;&#39;, label)) %&gt;% # remove unnecessary text select(variableId = name, label) # drop unnecessary columns and rename ## # A tibble: 6 x 2 ## variableId label ## &lt;chr&gt; &lt;chr&gt; ## 1 S0101_C01_002 Total!!Total population!!AGE!!Under 5 years ## 2 S0101_C02_002 Percent!!Total population!!AGE!!Under 5 years ## 3 S0101_C03_002 Male!!Total population!!AGE!!Under 5 years ## 4 S0101_C04_002 Percent Male!!Total population!!AGE!!Under 5 years ## 5 S0101_C05_002 Female!!Total population!!AGE!!Under 5 years ## 6 S0101_C06_002 Percent Female!!Total population!!AGE!!Under 5 years sVarnames %&gt;% filter(str_sub(name, 1, 5) == &quot;S0101&quot;) %&gt;% # search for these tables filter(str_detect(label, &quot;Under 5 years&quot;)) %&gt;% # search for variables mutate(label = sub(&#39;^Estimate!!&#39;, &#39;&#39;, label)) %&gt;% # remove unnecessary text select(variableId = name, label) # drop unnecessary columns and rename ## # A tibble: 6 x 2 ## variableId label ## &lt;chr&gt; &lt;chr&gt; ## 1 S0101_C01_002 Total!!Total population!!AGE!!Under 5 years ## 2 S0101_C02_002 Percent!!Total population!!AGE!!Under 5 years ## 3 S0101_C03_002 Male!!Total population!!AGE!!Under 5 years ## 4 S0101_C04_002 Percent Male!!Total population!!AGE!!Under 5 years ## 5 S0101_C05_002 Female!!Total population!!AGE!!Under 5 years ## 6 S0101_C06_002 Percent Female!!Total population!!AGE!!Under 5 years e.g per capita income, we can check on DP table variables. pVarnames %&gt;% filter(str_detect(label, &quot;Per capita&quot;)) %&gt;% # search for variables mutate(label = sub(&#39;^Estimate!!&#39;, &#39;&#39;, label)) %&gt;% # remove unnecessary text select(variable = name, label) # drop unnecessary columns and rename ## # A tibble: 2 x 2 ## variable label ## &lt;chr&gt; &lt;chr&gt; ## 1 DP03_0088 INCOME AND BENEFITS (IN 2018 INFLATION-ADJUSTED DOLLARS)!!Per capita income (dollars) ## 2 DP03_0088P Percent Estimate!!INCOME AND BENEFITS (IN 2018 INFLATION-ADJUSTED DOLLARS)!!Per capita income (dollars) pVarnames %&gt;% filter(str_detect(label, &quot;Under 5 years&quot;)) %&gt;% # search for variables mutate(label = sub(&#39;^Estimate!!&#39;, &#39;&#39;, label)) %&gt;% # remove unnecessary text select(variable = name, label) # drop unnecessary columns and rename ## # A tibble: 2 x 2 ## variable label ## &lt;chr&gt; &lt;chr&gt; ## 1 DP05_0005 SEX AND AGE!!Total population!!Under 5 years ## 2 DP05_0005P Percent Estimate!!SEX AND AGE!!Total population!!Under 5 years The order and structure of profile tables can change from year to year, hence the variable Id or label, so when downloading same dataset over different years we recommend using the standard B &amp; C tables. otherVarnames %&gt;% filter(str_detect(label, &quot;Per capita&quot;)) %&gt;% # search for variables mutate(label = sub(&#39;^Estimate!!&#39;, &#39;&#39;, label)) %&gt;% # remove unnecessary text select(variable = name, label) # drop unnecessary columns and rename ## # A tibble: 10 x 2 ## variable label ## &lt;chr&gt; &lt;chr&gt; ## 1 B19301_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 2 B19301A_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 3 B19301B_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 4 B19301C_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 5 B19301D_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 6 B19301E_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 7 B19301F_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 8 B19301G_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 9 B19301H_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) ## 10 B19301I_001 Per capita income in the past 12 months (in 2018 inflation-adjusted dollars) Contributors and Further Resources Contributors Moksha Menghaney, University of Chicago is the principal author of the initial version of this tutorial. Helpful improvements provided by Marynia Kolak. Email: mmenghaney@uchicago.edu for any issues/comments. "],
["link-contextual-data.html", "Link-contextual-data or Join", " Link-contextual-data or Join "],
["visualizeArealData-tutorial.html", "Visualize Areal Data - Choropleth Mapping (a.k.a Thematic Maps) Research Question Environment Setup Load data Thematic Plotting Appendix Contributors and Further Resources", " Visualize Areal Data - Choropleth Mapping (a.k.a Thematic Maps) Research Question Once we have downloaded the contextual data and generated the access metrics, we can start visualizing them to identify any spatial patterns. This can help identify whether a variable is homogeneously distributed across space or do we see clustering &amp; spatial heterogeneity. In this tutorial we will cover methods to plot data variables spatially i.e. create thematic maps, technically known as choropleth maps. We will cover the most commonly used types of choropleth mapping techniques employed in R. Please note the methods covered here are mere an introduction to spatial plotting. Environment Setup To replicate the codes &amp; functions illustrated in this tutorial, you’ll need to have R and RStudio downloaded and installed on your system. This tutorial assumes some familiarity with the R programming language. Packages used We will use the following packages in this tutorial: tidyverse: to manipulate data tmap: to visualize and create maps sf: to read/write and manipulate spatial data Required Inputs and Expected Outputs We will using the race data for Illinois downloaded &amp; saved as a shapefile using the get-ACS_Data tutorial from the Census Bureau. Our output will be three thematic maps highlighting the distribution of percentage hispanic population at a county level across the state of Illinois. Install and load the packages First, install and load the relevant R packages with the following commands: install.packages(&quot;tidyverse&quot;) install.packages(&quot;tmap&quot;) install.packages(&quot;sf&quot;) library(tidyverse) library(tmap) library(sf) Load data We will read in the shapefile with percentage hispanic population at the county level for the state of Illinois for year 2018. pctHispanic &lt;- st_read(&quot;IL_County_18.shp&quot;) Alternatively, if you have not saved the dataset from get-ACS-Data tutorial, you can download it using the code below or from the box folder here. require(tidycensus) pctHispanic &lt;- tidycensus::get_acs(geography = &#39;county&#39;, state = &#39;IL&#39;, variables = c(totPop18 = &quot;B01001_001&quot;, hispanic =&quot;B03003_003&quot;, notHispanic = &quot;B03003_002&quot;, white = &quot;B02001_002&quot;, afrAm = &quot;B02001_003&quot;, asian = &quot;B02001_005&quot;), year = 2018, geometry = TRUE) %&gt;% select(GEOID, NAME, variable, estimate) %&gt;% spread(variable, estimate) %&gt;% mutate(hispPr18 = hispanic/totPop18, WhitePr18 = white/totPop18, AfrAmPr18 = afrAm/totPop18, AsianPr18 = asian/totPop18) %&gt;% select(GEOID,totPop18,hispPr18,WhitePr18,AfrAmPr18, AsianPr18) Lets check the dataset structure. head(pctHispanic) ## Simple feature collection with 6 features and 6 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -91.51308 ymin: 36.9703 xmax: -88.70541 ymax: 42.49505 ## geographic CRS: NAD83 ## GEOID totPop18 hispPr18 WhitePr18 AfrAmPr18 AsianPr18 geometry ## 1 17001 66427 0.01537026 0.9306306 0.040826772 0.0081292246 MULTIPOLYGON (((-91.51297 4... ## 2 17003 6532 0.01117575 0.6243111 0.332057563 0.0009185548 MULTIPOLYGON (((-89.51839 3... ## 3 17005 16712 0.03458593 0.9088679 0.062410244 0.0117280996 MULTIPOLYGON (((-89.63926 3... ## 4 17007 53606 0.21376338 0.8741745 0.022199008 0.0118083797 MULTIPOLYGON (((-88.94098 4... ## 5 17009 6675 0.04284644 0.7742322 0.204344569 0.0055430712 MULTIPOLYGON (((-90.91703 3... ## 6 17011 33381 0.08972170 0.9361613 0.009316677 0.0086576196 MULTIPOLYGON (((-89.86235 4... In a shapefile, the ‘geometry’ column provides the geographic information/boundaries that we can map. We can do a quick plot using: plot(pctHispanic$geometry) Before we move ahead, lets convert the percentages for easy plotting. pctHispanic &lt;- pctHispanic %&gt;% mutate_at(vars(hispPr18:AsianPr18), .funs = funs(round(. * 100,2))) Thematic Plotting We will be using tmap package for plotting spatial data distributions. The package syntax has similarities with ggplot2 and follows the same idea of A Layered Grammar of Graphics. for each input data layer use tm_shape(), followed by the method to plot it, e.g tm_fill() or tm_dots() or tm_line() or tm_borders() etc. Similar to ggplot2, aesthetics can be provided for each layer and plot layout can be manipulated using tm_layout(). For more details on tmap usage &amp; functionality, check tmap documentation. The previous map we plotted using plot can be mapped using tmap as in the code below. tmap_mode(&#39;plot&#39;) ## tmap mode set to plotting tm_shape(pctHispanic) + tm_borders() + tm_layout(frame = FALSE) In tmap, the classification scheme is set by the style option in tm_fill() and the default style is pretty. Lets plot the distribution of percentage of hispanic population by county across the state of Illinois with default style using the code below. We can also change the color palette used to depict the spatial distribution. See Set Color Palette in Appendix for more details on that. tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Pretty&#39;) + tm_borders() + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size = 0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) We will be plotting the spatial distribution of variable hispPr18 for the state of Illinois using three methods. Quantile Natural Breaks Standard Deviation For detailed documentation on choropleth mapping and methods use check GeoDa Center Documentation. Quantile A quantile map is based on sorted values for the variable that are then grouped into bins such that each bin has the same number of observations. It is obtained by setting style = 'quantile' and n = no of bins arguments in tm_fill(). p1 &lt;- tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Quantile&#39;, style = &#39;quantile&#39;, n = 5) + tm_borders() + tm_layout(frame = FALSE,legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) #tmap_save(p1, &#39;PctHisp_18_Quantile.png&#39;) # save the map in a .png file p1 Natural Breaks Natural breaks or jenks distribution uses a nonlinear algorithm to cluster data into groups such that the intra-bin similarity is maximized and inter-bin dissimilarity is minimized. It is obtained by setting style = 'jenks' and n = no. of bins in the tm_fill(). As we can see, jenks method better classifies the dataset in review than the quantile distribution. There is no correct method to use and the choice of classification method is dependent on the problem &amp; dataset used. p2 &lt;- tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Jenks&#39;, style = &#39;jenks&#39;, n = 5) + tm_borders() + tm_layout(frame = FALSE,legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) #tmap_save(p2, &#39;PctHisp_18_Jenks.png&#39;)# save the map in a .png file p2 Standard Deviation A standard deviation map normalizes the dataset (mean = 0, stdev = 1) and transforms it into units of stdev (given mean =0). It helps identify outliers in the dataset. It is obtained by setting style = 'sd' in the tm_fill(). The normalization process can create bins with negative values, which in this case don’t necessarily make sense for the dataset, but it still helps identify the outliers. p3 &lt;- tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Stdev&#39;, style = &#39;sd&#39;) + tm_borders() + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) #tmap_save(p3, &#39;PctHisp_18_Stdev.png&#39;)# save the map in a .png file p3 Appendix Set Color Palette The range of colors used to depict the distribution in the map can be set by modifying the palette argument in tm_fill(). For example, we can use Blues palette to create the map below. tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Jenks&#39;, style = &#39;jenks&#39;, n = 5, palette = &#39;Blues&#39;) + tm_borders() + tm_layout(frame = FALSE,legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) Use ColorBrewer To build aesthetically pleasing and easy-to-read maps, we recommend using color palette schemes recommended in ColorBrewer 2.0 developed by Cynthia Brewer. The website distinguishes between sequential(ordered), diverging(spread around a center) &amp; qualitative(categorical) data. Information on these palettes cab be displayed in R using RColorBrewer package. We can get the hex values for the colors used in a specific palette with n bins &amp; plot the corresponding colors using code below. require(RColorBrewer) RColorBrewer::brewer.pal(5,&quot;PuBuGn&quot;) ## [1] &quot;#F6EFF7&quot; &quot;#BDC9E1&quot; &quot;#67A9CF&quot; &quot;#1C9099&quot; &quot;#016C59&quot; RColorBrewer::display.brewer.pal(5,&quot;PuBuGn&quot;) We can update the jenks map by using this sequential color scheme and changing the transparency using alpha = 0.8 as below. tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Jenks&#39;, style = &#39;jenks&#39;, n = 5, palette = &#39;PuBuGn&#39;) + tm_borders() + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) We can also update the stdev map by using a diverging color scheme as below. tm_shape(pctHispanic) + tm_fill(&#39;hispPr18&#39;, title = &#39;PctHispanic% - Stdev&#39;, style = &#39;sd&#39;, palette = &#39;-RdBu&#39;, alpha = 0.9) + tm_borders() + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Pct of hispanic population by county, IL 2018&#39;, main.title.size = 0.9) Example - using ColorBrewer for US wide datasets Download and plot the distribution of median household income in US by county for year 2018. require(tidycensus) medianHHInc &lt;- tidycensus::get_acs(&#39;county&#39;, variables = c(median_HHInc = &#39;B19013_001&#39;), year = 2018, geometry = TRUE, output = &#39;wide&#39;) medianHHInc &lt;- medianHHInc %&gt;% separate(NAME, c(&quot;CountyName&quot;, &quot;State&quot;), sep = &#39;, &#39;) %&gt;% filter(!(State %in% c(&#39;Puerto Rico&#39;,&#39;Alaska&#39;,&#39;Hawaii&#39;))) ## contiguous US tm_shape(medianHHInc) + tm_fill(&#39;median_HHIncE&#39;, title = &#39;Median Household Income $ - Jenks&#39;, style = &#39;jenks&#39;, n = 7, palette = &#39;PuBuGn&#39;) + tm_borders(alpha = 0.4) + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &#39;right&#39;, legend.title.size =0.9, main.title = &#39;Distribution of Household Income, by county, US 2018&#39;, main.title.position = c(&#39;center&#39;,&#39;top&#39;), main.title.size = 0.9) Contributors and Further Resources Contributors Moksha Menghaney, University of Chicago is the principal author of the initial version of this tutorial. Helpful improvements provided by Marynia Kolak. Email: mmenghaney@uchicago.edu for any issues/comments. "]
]
